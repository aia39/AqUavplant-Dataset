{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8349901,"sourceType":"datasetVersion","datasetId":4960812},{"sourceId":8394606,"sourceType":"datasetVersion","datasetId":4992853}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport scipy.io\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport time\nimport re\nimport cv2\nimport math\n\n\nBATCH_SIZE = 4","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-18T08:50:57.175576Z","iopub.execute_input":"2024-05-18T08:50:57.176352Z","iopub.status.idle":"2024-05-18T08:50:57.182465Z","shell.execute_reply.started":"2024-05-18T08:50:57.176321Z","shell.execute_reply":"2024-05-18T08:50:57.181471Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# import os\n\n# # Define the root directory\n# root_dir = '/kaggle/input/aquatic-another/Test'\n\n# list_of_folders = []\n\n# # Walk through all directories and subdirectories\n# for root, dirs, files in os.walk(root_dir):\n#     for directory in dirs:\n#         if('frame' in directory):\n#             list_of_folders.append(os.path.join(root, directory))\n#         #print(os.path.join(root, directory))\n# len(list_of_folders)\n# list_of_folders","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:50:57.578870Z","iopub.execute_input":"2024-05-18T08:50:57.579674Z","iopub.status.idle":"2024-05-18T08:50:57.584009Z","shell.execute_reply.started":"2024-05-18T08:50:57.579643Z","shell.execute_reply":"2024-05-18T08:50:57.582786Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# import os\n\n# # Define the directory path\n# directory_path = '/kaggle/input/aquatic-another/Test'\n\n# # Get a list of all files and directories in the specified directory\n# contents = os.listdir(directory_path)\n\n# # Filter out only the directories\n# folders = [folder for folder in contents if os.path.isdir(os.path.join(directory_path, folder))]\n\n# # Print the list of folders\n# for i in folders:\n#     sub = os.path.join(directory_path, i)\n#     aa = os.listdir(sub)\n#     print(aa)\n#     break","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:50:57.997558Z","iopub.execute_input":"2024-05-18T08:50:57.998378Z","iopub.status.idle":"2024-05-18T08:50:58.002800Z","shell.execute_reply.started":"2024-05-18T08:50:57.998349Z","shell.execute_reply":"2024-05-18T08:50:58.001686Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# #sub.split('/')[-1]\n# import re\n\n# def find_numerical_part(string):\n#     # Use regex to find numerical part in the string\n#     numerical_part = re.findall(r'\\d+', string)[0]\n#     return numerical_part\n\n# numeral = find_numerical_part(aa[0])\n# numeral\n\n# n = sub.split('/')[-1]\n# print(f'{n}_{numeral}_binary.png')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:50:58.349587Z","iopub.execute_input":"2024-05-18T08:50:58.350336Z","iopub.status.idle":"2024-05-18T08:50:58.354413Z","shell.execute_reply.started":"2024-05-18T08:50:58.350308Z","shell.execute_reply":"2024-05-18T08:50:58.353377Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# import cv2\n# import os\n# import re\n\n# def find_numerical_part(string):\n#     # Use regex to find numerical part in the string\n#     numerical_part = re.findall(r'\\d+', string)[0]\n#     return numerical_part\n\n# main = os.path.join(sub,aa[0])\n# numeral = find_numerical_part(aa[0])\n# n = sub.split('/')[-1]\n# image_path = os.path.join(main, f'{n}_{numeral}_binary.png')\n# mask = cv2.imread(image_path)\n# mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n\n# raw_imggg = os.path.join(main, f'frame_{numeral}.jpg')\n# raw_img = cv2.imread(raw_imggg)\n\n# #gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# #image = (image/max(image.ravel()))*255\n# # cv2.imshow('Image', image)\n# # cv2.waitKey(0)\n# # cv2.destroyAllWindows()\n# print(np.unique(mask))\n# # cv2.imwrite('sample.png',mask)\n# # cv2.imwrite('raw.png',raw_img)\n\n# print(mask.shape, raw_img.shape)\n\n# mmm = np.transpose(mask, axes=(2, 0, 1))\n# print(mmm.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:50:58.701252Z","iopub.execute_input":"2024-05-18T08:50:58.702116Z","iopub.status.idle":"2024-05-18T08:50:58.706618Z","shell.execute_reply.started":"2024-05-18T08:50:58.702084Z","shell.execute_reply":"2024-05-18T08:50:58.705600Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def find_numerical_part(string):\n    # Use regex to find numerical part in the string\n    numerical_part = re.findall(r'\\d+', string)[0]\n    return numerical_part\n\n\nclass aquatic_plant_dataset:\n    def __init__(self, imagePaths, transforms, mode, img_target_shape = 512):\n        # store the image and mask filepaths, and augmentation\n        self.imagePaths = imagePaths\n        #self.maskPaths = maskPaths\n        self.transforms = transforms\n        self.mode = mode\n        self.train_list = []\n        self.val_list = []\n        self.test_list = []\n        self.target_shape = (img_target_shape, img_target_shape)\n        \n        if(self.mode == 'train'):\n            root_dir = self.imagePaths\n            # Walk through all directories and subdirectories\n            for root, dirs, files in os.walk(self.imagePaths):\n                for directory in dirs:\n                    if('frame' in directory):\n                        self.train_list.append(os.path.join(root, directory))\n        \n        elif(self.mode == 'val'):\n            # Walk through all directories and subdirectories\n            for root, dirs, files in os.walk(self.imagePaths):\n                for directory in dirs:\n                    if('frame' in directory):\n                        self.val_list.append(os.path.join(root, directory))\n                        \n        else:\n            # Walk through all directories and subdirectories\n            for root, dirs, files in os.walk(self.imagePaths):\n                for directory in dirs:\n                    if('frame' in directory):\n                        self.test_list.append(os.path.join(root, directory))\n\n        \n    def __len__(self):\n        if(self.mode == 'train'):\n            return len(self.train_list)\n        elif(self.mode == 'val'):\n            return len(self.val_list)\n        else:\n            return len(self.test_list)\n    \n    def __getitem__(self,idx):\n        if(self.mode == 'train'):\n            folder_dir = self.train_list[idx]\n            frame_name = folder_dir.split('/')[-1]\n            loc_name = folder_dir.split('/')[-2]\n            numeral = find_numerical_part(frame_name)\n            image_path = os.path.join(folder_dir, f'{loc_name}_{numeral}_binary.png')  \n            binary_mask = cv2.imread(image_path)  ##reading raw image\n            binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_BGR2GRAY)\n            #print(image_path)\n            \n            raw_path = os.path.join(folder_dir, f'frame_{numeral}.jpg')  ##reading the raw file\n            raw_img = cv2.imread(raw_path)  ##reading raw image\n            #print(folder_dir, raw_path)\n            #print(raw_img.shape)\n        \n        elif(self.mode == 'val'):\n            folder_dir = self.val_list[idx]\n            frame_name = folder_dir.split('/')[-1]\n            loc_name = folder_dir.split('/')[-2]\n            numeral = find_numerical_part(frame_name)\n            image_path = os.path.join(folder_dir, f'{loc_name}_{numeral}_binary.png')  \n            binary_mask = cv2.imread(image_path)  ##reading raw image\n            binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_BGR2GRAY)\n            #binary_mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            raw_path = os.path.join(folder_dir, f'frame_{numeral}.jpg')  ##reading the raw file\n            raw_img = cv2.imread(raw_path)  ##reading raw image\n        \n        else:\n            folder_dir = self.test_list[idx]\n            frame_name = folder_dir.split('/')[-1]\n            loc_name = folder_dir.split('/')[-2]\n            numeral = find_numerical_part(frame_name)\n            image_path = os.path.join(folder_dir, f'{loc_name}_{numeral}_binary.png')  \n            binary_mask = cv2.imread(image_path)  ##reading raw image\n            binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_BGR2GRAY)\n            \n            #binary_mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            raw_path = os.path.join(folder_dir, f'frame_{numeral}.jpg')  ##reading the raw file\n            raw_img = cv2.imread(raw_path)  ##reading raw image\n        \n        if(self.transforms is not None):\n            target_size = self.target_shape\n            raw_img = cv2.resize(raw_img, target_size)\n            binary_mask = cv2.resize(binary_mask, target_size)\n\n            \n        raw_img = np.transpose(raw_img, axes=(2, 0, 1))\n        binary_mask = np.expand_dims(binary_mask, axis=0)\n        #binary_mask = np.transpose(binary_mask, axes=(2, 0, 1))\n        \n        return torch.from_numpy(raw_img),torch.from_numpy(binary_mask)\n              \n        \ntrain_dataset = aquatic_plant_dataset('/kaggle/input/final-run/Stratified_split/Train', True, 'train')\nval_dataset = aquatic_plant_dataset('/kaggle/input/final-run/Stratified_split/Validation', True, 'val')\ntest_dataset = aquatic_plant_dataset('/kaggle/input/final-run/Stratified_split/Test', True, 'test')\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers = 0)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size = BATCH_SIZE, num_workers = 0)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, num_workers = 0)   ##in testset batchsize is 1","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:50:59.296254Z","iopub.execute_input":"2024-05-18T08:50:59.296687Z","iopub.status.idle":"2024-05-18T08:51:00.126051Z","shell.execute_reply.started":"2024-05-18T08:50:59.296659Z","shell.execute_reply":"2024-05-18T08:51:00.125082Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nlen(test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:51:00.127822Z","iopub.execute_input":"2024-05-18T08:51:00.128444Z","iopub.status.idle":"2024-05-18T08:51:00.189437Z","shell.execute_reply.started":"2024-05-18T08:51:00.128412Z","shell.execute_reply":"2024-05-18T08:51:00.188530Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{}}]},{"cell_type":"markdown","source":"https://github.com/LeeJunHyun/Image_Segmentation/blob/master/network.py\n\nDifferent models","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\n\ndef init_weights(net, init_type='normal', gain=0.02):\n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n            if init_type == 'normal':\n                init.normal_(m.weight.data, 0.0, gain)\n            elif init_type == 'xavier':\n                init.xavier_normal_(m.weight.data, gain=gain)\n            elif init_type == 'kaiming':\n                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n            elif init_type == 'orthogonal':\n                init.orthogonal_(m.weight.data, gain=gain)\n            else:\n                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n            if hasattr(m, 'bias') and m.bias is not None:\n                init.constant_(m.bias.data, 0.0)\n        elif classname.find('BatchNorm2d') != -1:\n            init.normal_(m.weight.data, 1.0, gain)\n            init.constant_(m.bias.data, 0.0)\n\n    print('initialize network with %s' % init_type)\n    net.apply(init_func)\n\nclass conv_block(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(conv_block,self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n\n    def forward(self,x):\n        x = self.conv(x)\n        return x\n\nclass up_conv(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(up_conv,self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n\t\t    nn.BatchNorm2d(ch_out),\n\t\t\tnn.ReLU(inplace=True)\n        )\n\n    def forward(self,x):\n        x = self.up(x)\n        return x\n\nclass Recurrent_block(nn.Module):\n    def __init__(self,ch_out,t=2):\n        super(Recurrent_block,self).__init__()\n        self.t = t\n        self.ch_out = ch_out\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n\t\t    nn.BatchNorm2d(ch_out),\n\t\t\tnn.ReLU(inplace=True)\n        )\n\n    def forward(self,x):\n        for i in range(self.t):\n\n            if i==0:\n                x1 = self.conv(x)\n            \n            x1 = self.conv(x+x1)\n        return x1\n        \nclass RRCNN_block(nn.Module):\n    def __init__(self,ch_in,ch_out,t=2):\n        super(RRCNN_block,self).__init__()\n        self.RCNN = nn.Sequential(\n            Recurrent_block(ch_out,t=t),\n            Recurrent_block(ch_out,t=t)\n        )\n        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n\n    def forward(self,x):\n        x = self.Conv_1x1(x)\n        x1 = self.RCNN(x)\n        return x+x1\n\n\nclass single_conv(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(single_conv,self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self,x):\n        x = self.conv(x)\n        return x\n\nclass Attention_block(nn.Module):\n    def __init__(self,F_g,F_l,F_int):\n        super(Attention_block,self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n            )\n        \n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n        \n        self.relu = nn.ReLU(inplace=True)\n        \n    def forward(self,g,x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1+x1)\n        psi = self.psi(psi)\n\n        return x*psi","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:51:01.250531Z","iopub.execute_input":"2024-05-18T08:51:01.250956Z","iopub.status.idle":"2024-05-18T08:51:01.421481Z","shell.execute_reply.started":"2024-05-18T08:51:01.250920Z","shell.execute_reply":"2024-05-18T08:51:01.420484Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# U_Net","metadata":{}},{"cell_type":"code","source":"# class U_Net(nn.Module):\n#     def __init__(self,img_ch=3,output_ch=1):\n#         super(U_Net,self).__init__()\n        \n#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n#         self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n#         self.Conv2 = conv_block(ch_in=64,ch_out=128)\n#         self.Conv3 = conv_block(ch_in=128,ch_out=256)\n#         self.Conv4 = conv_block(ch_in=256,ch_out=512)\n#         self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n\n#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n#         self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n\n#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n#         self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n        \n#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n#         self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n        \n#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n#         self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n\n#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n#     def forward(self,x):\n#         # encoding path\n#         x1 = self.Conv1(x)\n#         x2 = self.Maxpool(x1)\n#         x2 = self.Conv2(x2)\n#         x3 = self.Maxpool(x2)\n#         x3 = self.Conv3(x3)\n#         x4 = self.Maxpool(x3)\n#         x4 = self.Conv4(x4)\n#         x5 = self.Maxpool(x4)\n#         x5 = self.Conv5(x5)\n\n#         # decoding + concat path\n#         d5 = self.Up5(x5)\n#         d5 = torch.cat((x4,d5),dim=1)\n        \n#         d5 = self.Up_conv5(d5)\n        \n#         d4 = self.Up4(d5)\n#         d4 = torch.cat((x3,d4),dim=1)\n#         d4 = self.Up_conv4(d4)\n\n#         d3 = self.Up3(d4)\n#         d3 = torch.cat((x2,d3),dim=1)\n#         d3 = self.Up_conv3(d3)\n\n#         d2 = self.Up2(d3)\n#         d2 = torch.cat((x1,d2),dim=1)\n#         d2 = self.Up_conv2(d2)\n\n#         d1 = self.Conv_1x1(d2)\n\n#         return d1\n\n# model = U_Net().to(device)\n# print(model)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-14T17:52:04.472732Z","iopub.execute_input":"2024-05-14T17:52:04.473103Z","iopub.status.idle":"2024-05-14T17:52:04.481960Z","shell.execute_reply.started":"2024-05-14T17:52:04.473062Z","shell.execute_reply":"2024-05-14T17:52:04.481079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# R2U_Net","metadata":{}},{"cell_type":"code","source":"# class R2U_Net(nn.Module):\n#     def __init__(self,img_ch=3,output_ch=1,t=2):\n#         super(R2U_Net,self).__init__()\n        \n#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n#         self.Upsample = nn.Upsample(scale_factor=2)\n\n#         self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n\n#         self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n        \n#         self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n        \n#         self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n        \n#         self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n        \n\n#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n#         self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n        \n#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n#         self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n        \n#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n#         self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n        \n#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n#         self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n\n#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n#     def forward(self,x):\n#         # encoding path\n#         x1 = self.RRCNN1(x)\n\n#         x2 = self.Maxpool(x1)\n#         x2 = self.RRCNN2(x2)\n        \n#         x3 = self.Maxpool(x2)\n#         x3 = self.RRCNN3(x3)\n\n#         x4 = self.Maxpool(x3)\n#         x4 = self.RRCNN4(x4)\n\n#         x5 = self.Maxpool(x4)\n#         x5 = self.RRCNN5(x5)\n\n#         # decoding + concat path\n#         d5 = self.Up5(x5)\n#         d5 = torch.cat((x4,d5),dim=1)\n#         d5 = self.Up_RRCNN5(d5)\n        \n#         d4 = self.Up4(d5)\n#         d4 = torch.cat((x3,d4),dim=1)\n#         d4 = self.Up_RRCNN4(d4)\n\n#         d3 = self.Up3(d4)\n#         d3 = torch.cat((x2,d3),dim=1)\n#         d3 = self.Up_RRCNN3(d3)\n\n#         d2 = self.Up2(d3)\n#         d2 = torch.cat((x1,d2),dim=1)\n#         d2 = self.Up_RRCNN2(d2)\n\n#         d1 = self.Conv_1x1(d2)\n\n#         return d1\n    \n# model = R2U_Net().to(device)\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:52:04.485109Z","iopub.execute_input":"2024-05-14T17:52:04.485585Z","iopub.status.idle":"2024-05-14T17:52:04.492817Z","shell.execute_reply.started":"2024-05-14T17:52:04.485560Z","shell.execute_reply":"2024-05-14T17:52:04.491994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AttU_Net","metadata":{}},{"cell_type":"code","source":"# class AttU_Net(nn.Module):\n#     def __init__(self,img_ch=3,output_ch=1):\n#         super(AttU_Net,self).__init__()\n        \n#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n#         self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n#         self.Conv2 = conv_block(ch_in=64,ch_out=128)\n#         self.Conv3 = conv_block(ch_in=128,ch_out=256)\n#         self.Conv4 = conv_block(ch_in=256,ch_out=512)\n#         self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n\n#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n#         self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n#         self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n\n#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n#         self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n#         self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n        \n#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n#         self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n#         self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n        \n#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n#         self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n#         self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n\n#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n#     def forward(self,x):\n#         # encoding path\n#         x1 = self.Conv1(x)\n\n#         x2 = self.Maxpool(x1)\n#         x2 = self.Conv2(x2)\n        \n#         x3 = self.Maxpool(x2)\n#         x3 = self.Conv3(x3)\n\n#         x4 = self.Maxpool(x3)\n#         x4 = self.Conv4(x4)\n\n#         x5 = self.Maxpool(x4)\n#         x5 = self.Conv5(x5)\n\n#         # decoding + concat path\n#         d5 = self.Up5(x5)\n#         x4 = self.Att5(g=d5,x=x4)\n#         d5 = torch.cat((x4,d5),dim=1)        \n#         d5 = self.Up_conv5(d5)\n        \n#         d4 = self.Up4(d5)\n#         x3 = self.Att4(g=d4,x=x3)\n#         d4 = torch.cat((x3,d4),dim=1)\n#         d4 = self.Up_conv4(d4)\n\n#         d3 = self.Up3(d4)\n#         x2 = self.Att3(g=d3,x=x2)\n#         d3 = torch.cat((x2,d3),dim=1)\n#         d3 = self.Up_conv3(d3)\n\n#         d2 = self.Up2(d3)\n#         x1 = self.Att2(g=d2,x=x1)\n#         d2 = torch.cat((x1,d2),dim=1)\n#         d2 = self.Up_conv2(d2)\n\n#         d1 = self.Conv_1x1(d2)\n\n#         return d1\n    \n    \n# model = AttU_Net().to(device)\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:52:04.494008Z","iopub.execute_input":"2024-05-14T17:52:04.494321Z","iopub.status.idle":"2024-05-14T17:52:05.106737Z","shell.execute_reply.started":"2024-05-14T17:52:04.494291Z","shell.execute_reply":"2024-05-14T17:52:05.105824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# R2AttU_Net","metadata":{}},{"cell_type":"code","source":"# class R2AttU_Net(nn.Module):\n#     def __init__(self,img_ch=3,output_ch=1,t=2):\n#         super(R2AttU_Net,self).__init__()\n        \n#         self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n#         self.Upsample = nn.Upsample(scale_factor=2)\n\n#         self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n\n#         self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n        \n#         self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n        \n#         self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n        \n#         self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n        \n\n#         self.Up5 = up_conv(ch_in=1024,ch_out=512)\n#         self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n#         self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n        \n#         self.Up4 = up_conv(ch_in=512,ch_out=256)\n#         self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n#         self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n        \n#         self.Up3 = up_conv(ch_in=256,ch_out=128)\n#         self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n#         self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n        \n#         self.Up2 = up_conv(ch_in=128,ch_out=64)\n#         self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n#         self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n\n#         self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n#     def forward(self,x):\n#         # encoding path\n#         x1 = self.RRCNN1(x)\n\n#         x2 = self.Maxpool(x1)\n#         x2 = self.RRCNN2(x2)\n        \n#         x3 = self.Maxpool(x2)\n#         x3 = self.RRCNN3(x3)\n\n#         x4 = self.Maxpool(x3)\n#         x4 = self.RRCNN4(x4)\n\n#         x5 = self.Maxpool(x4)\n#         x5 = self.RRCNN5(x5)\n\n#         # decoding + concat path\n#         d5 = self.Up5(x5)\n#         x4 = self.Att5(g=d5,x=x4)\n#         d5 = torch.cat((x4,d5),dim=1)\n#         d5 = self.Up_RRCNN5(d5)\n        \n#         d4 = self.Up4(d5)\n#         x3 = self.Att4(g=d4,x=x3)\n#         d4 = torch.cat((x3,d4),dim=1)\n#         d4 = self.Up_RRCNN4(d4)\n\n#         d3 = self.Up3(d4)\n#         x2 = self.Att3(g=d3,x=x2)\n#         d3 = torch.cat((x2,d3),dim=1)\n#         d3 = self.Up_RRCNN3(d3)\n\n#         d2 = self.Up2(d3)\n#         x1 = self.Att2(g=d2,x=x1)\n#         d2 = torch.cat((x1,d2),dim=1)\n#         d2 = self.Up_RRCNN2(d2)\n\n#         d1 = self.Conv_1x1(d2)\n\n#         return d1\n    \n# model = R2AttU_Net().to(device)\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:52:05.108084Z","iopub.execute_input":"2024-05-14T17:52:05.108446Z","iopub.status.idle":"2024-05-14T17:52:05.115514Z","shell.execute_reply.started":"2024-05-14T17:52:05.108398Z","shell.execute_reply":"2024-05-14T17:52:05.114550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deeplabv3","metadata":{}},{"cell_type":"code","source":"###Deeplabv3\n\nfrom torchvision.models.segmentation import deeplabv3_resnet50, deeplabv3_resnet101, deeplabv3_mobilenet_v3_large\nfrom torchvision.models.segmentation import (\n                                            DeepLabV3_ResNet50_Weights, \n                                             DeepLabV3_ResNet101_Weights, \n                                             DeepLabV3_MobileNet_V3_Large_Weights\n                                             )\n  \n#model_name == \"resnet_50\":\n#model = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n#transforms = DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n\n#model_name == \"resnet_101\":\nmodel = deeplabv3_resnet101()   #weights=DeepLabV3_ResNet101_Weights.DEFAULT\n#transforms = DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n\n#model_name == \"mobilenet\":\n#model = deeplabv3_mobilenet_v3_large(weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT)\n#transforms = DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n\nnew_conv_layer = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\nmodel.classifier[-1] = new_conv_layer\n\nmodel = model.to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:51:32.541847Z","iopub.execute_input":"2024-05-18T08:51:32.542174Z","iopub.status.idle":"2024-05-18T08:51:33.737201Z","shell.execute_reply.started":"2024-05-18T08:51:32.542151Z","shell.execute_reply":"2024-05-18T08:51:33.736269Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"DeepLabV3(\n  (backbone): IntermediateLayerGetter(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (6): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (7): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (8): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (9): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (10): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (11): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (12): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (13): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (14): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (15): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (16): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (17): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (18): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (19): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (20): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (21): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (22): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  (classifier): DeepLabHead(\n    (0): ASPP(\n      (convs): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ASPPConv(\n          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ASPPConv(\n          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (3): ASPPConv(\n          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (4): ASPPPooling(\n          (0): AdaptiveAvgPool2d(output_size=1)\n          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): ReLU()\n        )\n      )\n      (project): Sequential(\n        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU()\n    (4): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# img = np.random.randint(0, 255, size=(3, 100, 100)).astype(np.uint8)\n# img = torch.from_numpy(img).to(device)\n# pred = model(img)\n\n# last_layer = None\n# for layer in model.children():\n#     last_layer = layer\n# last_layer[4]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:52:05.128047Z","iopub.execute_input":"2024-05-14T17:52:05.128389Z","iopub.status.idle":"2024-05-14T17:52:05.136364Z","shell.execute_reply.started":"2024-05-14T17:52:05.128356Z","shell.execute_reply":"2024-05-14T17:52:05.135524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn import BCEWithLogitsLoss\nfrom torch.optim import Adam\n\nlossfunc = BCEWithLogitsLoss()\nlr = 1e-3\noptim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=2e-5)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:51:41.597226Z","iopub.execute_input":"2024-05-18T08:51:41.598021Z","iopub.status.idle":"2024-05-18T08:51:41.605426Z","shell.execute_reply.started":"2024-05-18T08:51:41.597987Z","shell.execute_reply":"2024-05-18T08:51:41.604408Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(\"Start training the network...\")\nstartTime = time.time()\n\nval_loss = []\ntrain_loss = []\nnum_epoch = 100\nbest_loss = math.inf\n\nfor epoch in tqdm(range(num_epoch)):\n    model.train()\n    totalTrainLoss = 0\n    totalTestLoss = 0\n    # loop over the training set\n    for (i, (raw, gt)) in enumerate(train_loader):\n        (raw, gt) = (raw.to(device), gt.to(device))\n        raw = raw.to(torch.float)\n        gt = gt.to(torch.float)\n        #print(raw.shape, gt.shape)\n        \n        pred = model(raw)[\"out\"]  #only for deeplabv3\n        #pred = model(raw)\n        \n        loss = lossfunc(pred, gt)\n\n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n        # add the loss to the total training loss so far\n        totalTrainLoss += loss\n        \n    train_loss.append(totalTrainLoss.detach().cpu().numpy())\n    \n    with torch.no_grad():\n        # set the model in evaluation mode\n        model.eval()\n        # loop over the validation set\n        for (raw, gt) in val_loader:\n            (raw, gt) = (raw.to(device), gt.to(device))\n            raw = raw.to(torch.float)\n            gt = gt.to(torch.float)\n            \n            pred = model(raw)[\"out\"]   ##only for deeplabv3\n            #pred = model(raw)\n            \n            curr_loss = lossfunc(pred, gt)\n            totalTestLoss += curr_loss\n    val_loss.append(totalTestLoss.detach().cpu().numpy()) \n    \n    if(totalTestLoss<best_loss):\n        print(f'Saving best weight at epoch: {epoch}.......')\n        torch.save(model.state_dict(), 'model_weights.pth')    \n        best_loss = totalTestLoss\n            \n    print(f\"Train loss: {totalTrainLoss/i}, Val loss: {totalTestLoss/i}\")\n    \n    print(\"EPOCH: {}/{}\".format(epoch + 1, num_epoch))\n    \n    #print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(avgTrainLoss, avgTestLoss))\n# display the total time needed to perform the training\nendTime = time.time()\nprint(\"total time taken to train the model: {:.2f}s\".format(endTime - startTime))","metadata":{"execution":{"iopub.status.busy":"2024-05-18T08:52:02.145126Z","iopub.execute_input":"2024-05-18T08:52:02.145716Z","iopub.status.idle":"2024-05-18T10:37:27.273562Z","shell.execute_reply.started":"2024-05-18T08:52:02.145688Z","shell.execute_reply":"2024-05-18T10:37:27.272511Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Start training the network...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Saving best weight at epoch: 0.......\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 1/100 [01:02<1:43:14, 62.57s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.6078988909721375, Val loss: 2.8725762367248535\nEPOCH: 1/100\nSaving best weight at epoch: 1.......\n","output_type":"stream"},{"name":"stderr","text":"  2%|         | 2/100 [02:06<1:43:39, 63.46s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.4469136893749237, Val loss: 0.45992252230644226\nEPOCH: 2/100\n","output_type":"stream"},{"name":"stderr","text":"  3%|         | 3/100 [03:10<1:42:44, 63.55s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.4109828472137451, Val loss: 3.7352840900421143\nEPOCH: 3/100\n","output_type":"stream"},{"name":"stderr","text":"  4%|         | 4/100 [04:13<1:41:39, 63.54s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.3778097927570343, Val loss: 0.6005297899246216\nEPOCH: 4/100\nSaving best weight at epoch: 4.......\n","output_type":"stream"},{"name":"stderr","text":"  5%|         | 5/100 [05:17<1:40:56, 63.75s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.3489609658718109, Val loss: 0.3693093955516815\nEPOCH: 5/100\nSaving best weight at epoch: 5.......\n","output_type":"stream"},{"name":"stderr","text":"  6%|         | 6/100 [06:22<1:40:03, 63.86s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.3317757248878479, Val loss: 0.11525776237249374\nEPOCH: 6/100\n","output_type":"stream"},{"name":"stderr","text":"  7%|         | 7/100 [07:25<1:38:51, 63.78s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.32106178998947144, Val loss: 1.0162594318389893\nEPOCH: 7/100\n","output_type":"stream"},{"name":"stderr","text":"  8%|         | 8/100 [08:29<1:37:37, 63.67s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.310519814491272, Val loss: 0.2572103440761566\nEPOCH: 8/100\n","output_type":"stream"},{"name":"stderr","text":"  9%|         | 9/100 [09:32<1:36:32, 63.65s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.2826368510723114, Val loss: 0.7843179106712341\nEPOCH: 9/100\n","output_type":"stream"},{"name":"stderr","text":" 10%|         | 10/100 [10:36<1:35:25, 63.62s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.2860613167285919, Val loss: 0.22509677708148956\nEPOCH: 10/100\nSaving best weight at epoch: 10.......\n","output_type":"stream"},{"name":"stderr","text":" 11%|         | 11/100 [11:40<1:34:32, 63.74s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.25870218873023987, Val loss: 0.11093323677778244\nEPOCH: 11/100\n","output_type":"stream"},{"name":"stderr","text":" 12%|        | 12/100 [12:43<1:33:26, 63.71s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.24064834415912628, Val loss: 1.3538124561309814\nEPOCH: 12/100\n","output_type":"stream"},{"name":"stderr","text":" 13%|        | 13/100 [13:47<1:32:19, 63.67s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.23903387784957886, Val loss: 0.8014510273933411\nEPOCH: 13/100\n","output_type":"stream"},{"name":"stderr","text":" 14%|        | 14/100 [14:51<1:31:13, 63.64s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.22006624937057495, Val loss: 0.7839678525924683\nEPOCH: 14/100\n","output_type":"stream"},{"name":"stderr","text":" 15%|        | 15/100 [15:54<1:30:06, 63.61s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21672433614730835, Val loss: 0.18659032881259918\nEPOCH: 15/100\n","output_type":"stream"},{"name":"stderr","text":" 16%|        | 16/100 [16:58<1:29:08, 63.67s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.2089068591594696, Val loss: 1.5900102853775024\nEPOCH: 16/100\n","output_type":"stream"},{"name":"stderr","text":" 17%|        | 17/100 [18:02<1:28:05, 63.68s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21490564942359924, Val loss: 1.027361273765564\nEPOCH: 17/100\n","output_type":"stream"},{"name":"stderr","text":" 18%|        | 18/100 [19:05<1:26:57, 63.63s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1948307305574417, Val loss: 0.175587996840477\nEPOCH: 18/100\n","output_type":"stream"},{"name":"stderr","text":" 19%|        | 19/100 [20:09<1:25:54, 63.63s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.19076727330684662, Val loss: 2.0143871307373047\nEPOCH: 19/100\n","output_type":"stream"},{"name":"stderr","text":" 20%|        | 20/100 [21:12<1:24:48, 63.61s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.194823756814003, Val loss: 0.1769433170557022\nEPOCH: 20/100\n","output_type":"stream"},{"name":"stderr","text":" 21%|        | 21/100 [22:16<1:23:44, 63.60s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.26013192534446716, Val loss: 0.21158118546009064\nEPOCH: 21/100\n","output_type":"stream"},{"name":"stderr","text":" 22%|       | 22/100 [23:20<1:22:41, 63.61s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.33046793937683105, Val loss: 14.070148468017578\nEPOCH: 22/100\n","output_type":"stream"},{"name":"stderr","text":" 23%|       | 23/100 [24:23<1:21:31, 63.53s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.3356693983078003, Val loss: 1.070883870124817\nEPOCH: 23/100\n","output_type":"stream"},{"name":"stderr","text":" 24%|       | 24/100 [25:26<1:20:20, 63.42s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.33693060278892517, Val loss: 0.12538863718509674\nEPOCH: 24/100\n","output_type":"stream"},{"name":"stderr","text":" 25%|       | 25/100 [26:29<1:19:14, 63.39s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.26146119832992554, Val loss: 0.7832680940628052\nEPOCH: 25/100\nSaving best weight at epoch: 25.......\n","output_type":"stream"},{"name":"stderr","text":" 26%|       | 26/100 [27:33<1:18:19, 63.51s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.2365361750125885, Val loss: 0.11093103140592575\nEPOCH: 26/100\n","output_type":"stream"},{"name":"stderr","text":" 27%|       | 27/100 [28:36<1:17:11, 63.45s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.22256147861480713, Val loss: 0.17911727726459503\nEPOCH: 27/100\n","output_type":"stream"},{"name":"stderr","text":" 28%|       | 28/100 [29:40<1:16:00, 63.34s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21939444541931152, Val loss: 0.48909473419189453\nEPOCH: 28/100\n","output_type":"stream"},{"name":"stderr","text":" 29%|       | 29/100 [30:43<1:14:56, 63.34s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1987753063440323, Val loss: 0.169080913066864\nEPOCH: 29/100\n","output_type":"stream"},{"name":"stderr","text":" 30%|       | 30/100 [31:46<1:13:53, 63.33s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.19959917664527893, Val loss: 0.7285342812538147\nEPOCH: 30/100\n","output_type":"stream"},{"name":"stderr","text":" 31%|       | 31/100 [32:50<1:12:50, 63.35s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1973058581352234, Val loss: 0.12580399215221405\nEPOCH: 31/100\nSaving best weight at epoch: 31.......\n","output_type":"stream"},{"name":"stderr","text":" 32%|      | 32/100 [33:54<1:11:59, 63.53s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.22512014210224152, Val loss: 0.08703859150409698\nEPOCH: 32/100\n","output_type":"stream"},{"name":"stderr","text":" 33%|      | 33/100 [34:57<1:10:52, 63.47s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.19217078387737274, Val loss: 0.1009998694062233\nEPOCH: 33/100\n","output_type":"stream"},{"name":"stderr","text":" 34%|      | 34/100 [36:00<1:09:48, 63.46s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.19348277151584625, Val loss: 1.2104450464248657\nEPOCH: 34/100\n","output_type":"stream"},{"name":"stderr","text":" 35%|      | 35/100 [37:04<1:08:40, 63.39s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.26212164759635925, Val loss: 0.10682795196771622\nEPOCH: 35/100\n","output_type":"stream"},{"name":"stderr","text":" 36%|      | 36/100 [38:07<1:07:32, 63.33s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.20983551442623138, Val loss: 0.2666468918323517\nEPOCH: 36/100\nSaving best weight at epoch: 36.......\n","output_type":"stream"},{"name":"stderr","text":" 37%|      | 37/100 [39:11<1:06:38, 63.48s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1874845176935196, Val loss: 0.082126684486866\nEPOCH: 37/100\n","output_type":"stream"},{"name":"stderr","text":" 38%|      | 38/100 [40:14<1:05:29, 63.37s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.18451720476150513, Val loss: 0.4482307732105255\nEPOCH: 38/100\n","output_type":"stream"},{"name":"stderr","text":" 39%|      | 39/100 [41:17<1:04:23, 63.34s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.17652441561222076, Val loss: 34.19890594482422\nEPOCH: 39/100\n","output_type":"stream"},{"name":"stderr","text":" 40%|      | 40/100 [42:20<1:03:23, 63.40s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.2270735502243042, Val loss: 10.051952362060547\nEPOCH: 40/100\n","output_type":"stream"},{"name":"stderr","text":" 41%|      | 41/100 [43:24<1:02:20, 63.40s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21273492276668549, Val loss: 0.10816001892089844\nEPOCH: 41/100\n","output_type":"stream"},{"name":"stderr","text":" 42%|     | 42/100 [44:27<1:01:15, 63.37s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21575243771076202, Val loss: 0.177572563290596\nEPOCH: 42/100\n","output_type":"stream"},{"name":"stderr","text":" 43%|     | 43/100 [45:30<1:00:05, 63.25s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.27628910541534424, Val loss: 4.6674346923828125\nEPOCH: 43/100\n","output_type":"stream"},{"name":"stderr","text":" 44%|     | 44/100 [46:33<58:57, 63.18s/it]  ","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.2251153439283371, Val loss: 0.08925063163042068\nEPOCH: 44/100\n","output_type":"stream"},{"name":"stderr","text":" 45%|     | 45/100 [47:36<57:50, 63.11s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.19719696044921875, Val loss: 0.08707720786333084\nEPOCH: 45/100\n","output_type":"stream"},{"name":"stderr","text":" 46%|     | 46/100 [48:39<56:47, 63.10s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.17084920406341553, Val loss: 0.11123023927211761\nEPOCH: 46/100\n","output_type":"stream"},{"name":"stderr","text":" 47%|     | 47/100 [49:42<55:46, 63.14s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.17375099658966064, Val loss: 0.09764058142900467\nEPOCH: 47/100\n","output_type":"stream"},{"name":"stderr","text":" 48%|     | 48/100 [50:45<54:41, 63.11s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1595722734928131, Val loss: 0.698361337184906\nEPOCH: 48/100\n","output_type":"stream"},{"name":"stderr","text":" 49%|     | 49/100 [51:49<53:40, 63.15s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.14818352460861206, Val loss: 0.11962001770734787\nEPOCH: 49/100\n","output_type":"stream"},{"name":"stderr","text":" 50%|     | 50/100 [52:52<52:38, 63.17s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.14066630601882935, Val loss: 0.12343978136777878\nEPOCH: 50/100\n","output_type":"stream"},{"name":"stderr","text":" 51%|     | 51/100 [53:55<51:36, 63.19s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.13779959082603455, Val loss: 0.1405486911535263\nEPOCH: 51/100\n","output_type":"stream"},{"name":"stderr","text":" 52%|    | 52/100 [54:58<50:33, 63.21s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.13452549278736115, Val loss: 0.16263823211193085\nEPOCH: 52/100\n","output_type":"stream"},{"name":"stderr","text":" 53%|    | 53/100 [56:02<49:32, 63.25s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1314784437417984, Val loss: 0.17111903429031372\nEPOCH: 53/100\n","output_type":"stream"},{"name":"stderr","text":" 54%|    | 54/100 [57:05<48:29, 63.25s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.13233672082424164, Val loss: 0.10971814393997192\nEPOCH: 54/100\n","output_type":"stream"},{"name":"stderr","text":" 55%|    | 55/100 [58:08<47:26, 63.25s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.12966537475585938, Val loss: 0.12769091129302979\nEPOCH: 55/100\n","output_type":"stream"},{"name":"stderr","text":" 56%|    | 56/100 [59:12<46:23, 63.27s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1300075352191925, Val loss: 0.15313149988651276\nEPOCH: 56/100\n","output_type":"stream"},{"name":"stderr","text":" 57%|    | 57/100 [1:00:15<45:20, 63.28s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.12698446214199066, Val loss: 0.09517309069633484\nEPOCH: 57/100\n","output_type":"stream"},{"name":"stderr","text":" 58%|    | 58/100 [1:01:18<44:17, 63.27s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.12400851398706436, Val loss: 0.1239403635263443\nEPOCH: 58/100\n","output_type":"stream"},{"name":"stderr","text":" 59%|    | 59/100 [1:02:21<43:13, 63.26s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.12218744307756424, Val loss: 0.13972985744476318\nEPOCH: 59/100\n","output_type":"stream"},{"name":"stderr","text":" 60%|    | 60/100 [1:03:25<42:10, 63.25s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11894003301858902, Val loss: 0.12786191701889038\nEPOCH: 60/100\n","output_type":"stream"},{"name":"stderr","text":" 61%|    | 61/100 [1:04:28<41:07, 63.27s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1182173639535904, Val loss: 0.12107120454311371\nEPOCH: 61/100\n","output_type":"stream"},{"name":"stderr","text":" 62%|   | 62/100 [1:05:31<40:06, 63.32s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.12428215146064758, Val loss: 0.12718528509140015\nEPOCH: 62/100\n","output_type":"stream"},{"name":"stderr","text":" 63%|   | 63/100 [1:06:35<39:04, 63.35s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.12160435318946838, Val loss: 0.15030579268932343\nEPOCH: 63/100\n","output_type":"stream"},{"name":"stderr","text":" 64%|   | 64/100 [1:07:38<38:00, 63.34s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1201196014881134, Val loss: 0.1386164128780365\nEPOCH: 64/100\n","output_type":"stream"},{"name":"stderr","text":" 65%|   | 65/100 [1:08:41<36:55, 63.30s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11833397299051285, Val loss: 0.14763307571411133\nEPOCH: 65/100\n","output_type":"stream"},{"name":"stderr","text":" 66%|   | 66/100 [1:09:44<35:51, 63.28s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11833591759204865, Val loss: 0.1703103631734848\nEPOCH: 66/100\n","output_type":"stream"},{"name":"stderr","text":" 67%|   | 67/100 [1:10:48<34:47, 63.26s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11337559670209885, Val loss: 0.12597399950027466\nEPOCH: 67/100\n","output_type":"stream"},{"name":"stderr","text":" 68%|   | 68/100 [1:11:51<33:46, 63.33s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1166902706027031, Val loss: 0.1250566840171814\nEPOCH: 68/100\n","output_type":"stream"},{"name":"stderr","text":" 69%|   | 69/100 [1:12:55<32:43, 63.33s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11268258094787598, Val loss: 0.11689914762973785\nEPOCH: 69/100\n","output_type":"stream"},{"name":"stderr","text":" 70%|   | 70/100 [1:13:58<31:40, 63.36s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11230940371751785, Val loss: 0.17035900056362152\nEPOCH: 70/100\n","output_type":"stream"},{"name":"stderr","text":" 71%|   | 71/100 [1:15:01<30:38, 63.40s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11260102689266205, Val loss: 0.10378304123878479\nEPOCH: 71/100\n","output_type":"stream"},{"name":"stderr","text":" 72%|  | 72/100 [1:16:05<29:35, 63.40s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11372746527194977, Val loss: 0.15285933017730713\nEPOCH: 72/100\n","output_type":"stream"},{"name":"stderr","text":" 73%|  | 73/100 [1:17:08<28:30, 63.36s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.12064997106790543, Val loss: 0.13230736553668976\nEPOCH: 73/100\n","output_type":"stream"},{"name":"stderr","text":" 74%|  | 74/100 [1:18:11<27:27, 63.37s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.11448630690574646, Val loss: 0.08424149453639984\nEPOCH: 74/100\n","output_type":"stream"},{"name":"stderr","text":" 75%|  | 75/100 [1:19:15<26:23, 63.34s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.10885313898324966, Val loss: 0.1797148436307907\nEPOCH: 75/100\n","output_type":"stream"},{"name":"stderr","text":" 76%|  | 76/100 [1:20:18<25:20, 63.37s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.10622742772102356, Val loss: 0.1940961629152298\nEPOCH: 76/100\n","output_type":"stream"},{"name":"stderr","text":" 77%|  | 77/100 [1:21:21<24:16, 63.34s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1498289704322815, Val loss: 1648086.375\nEPOCH: 77/100\n","output_type":"stream"},{"name":"stderr","text":" 78%|  | 78/100 [1:22:24<23:09, 63.16s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.44465065002441406, Val loss: 386.2383728027344\nEPOCH: 78/100\n","output_type":"stream"},{"name":"stderr","text":" 79%|  | 79/100 [1:23:27<22:02, 62.98s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.302875280380249, Val loss: 0.10799216479063034\nEPOCH: 79/100\n","output_type":"stream"},{"name":"stderr","text":" 80%|  | 80/100 [1:24:30<20:58, 62.91s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.24724526703357697, Val loss: 0.19841845333576202\nEPOCH: 80/100\n","output_type":"stream"},{"name":"stderr","text":" 81%|  | 81/100 [1:25:32<19:54, 62.85s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21986404061317444, Val loss: 0.10877572745084763\nEPOCH: 81/100\n","output_type":"stream"},{"name":"stderr","text":" 82%| | 82/100 [1:26:35<18:49, 62.77s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.20892639458179474, Val loss: 0.10527626425027847\nEPOCH: 82/100\n","output_type":"stream"},{"name":"stderr","text":" 83%| | 83/100 [1:27:38<17:46, 62.76s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.19450008869171143, Val loss: 0.13825556635856628\nEPOCH: 83/100\n","output_type":"stream"},{"name":"stderr","text":" 84%| | 84/100 [1:28:40<16:43, 62.74s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1906876564025879, Val loss: 0.15247686207294464\nEPOCH: 84/100\n","output_type":"stream"},{"name":"stderr","text":" 85%| | 85/100 [1:29:43<15:41, 62.79s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1664455384016037, Val loss: 0.1377037763595581\nEPOCH: 85/100\n","output_type":"stream"},{"name":"stderr","text":" 86%| | 86/100 [1:30:46<14:39, 62.80s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.15439052879810333, Val loss: 0.16246668994426727\nEPOCH: 86/100\n","output_type":"stream"},{"name":"stderr","text":" 87%| | 87/100 [1:31:49<13:36, 62.79s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1458565890789032, Val loss: 0.14953388273715973\nEPOCH: 87/100\n","output_type":"stream"},{"name":"stderr","text":" 88%| | 88/100 [1:32:52<12:33, 62.80s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.13889190554618835, Val loss: 0.1243007704615593\nEPOCH: 88/100\n","output_type":"stream"},{"name":"stderr","text":" 89%| | 89/100 [1:33:54<11:30, 62.82s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.14088356494903564, Val loss: 0.17762155830860138\nEPOCH: 89/100\n","output_type":"stream"},{"name":"stderr","text":" 90%| | 90/100 [1:34:57<10:28, 62.80s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.15433131158351898, Val loss: 0.1601184755563736\nEPOCH: 90/100\n","output_type":"stream"},{"name":"stderr","text":" 91%| | 91/100 [1:36:00<09:26, 62.90s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.17105978727340698, Val loss: 0.1564924418926239\nEPOCH: 91/100\n","output_type":"stream"},{"name":"stderr","text":" 92%|| 92/100 [1:37:03<08:23, 62.88s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.18497875332832336, Val loss: 0.4223076403141022\nEPOCH: 92/100\n","output_type":"stream"},{"name":"stderr","text":" 93%|| 93/100 [1:38:06<07:19, 62.83s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21156540513038635, Val loss: 6.638162612915039\nEPOCH: 93/100\n","output_type":"stream"},{"name":"stderr","text":" 94%|| 94/100 [1:39:09<06:16, 62.80s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21668139100074768, Val loss: 11106.32421875\nEPOCH: 94/100\n","output_type":"stream"},{"name":"stderr","text":" 95%|| 95/100 [1:40:11<05:13, 62.76s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.26516908407211304, Val loss: 0.1824864000082016\nEPOCH: 95/100\n","output_type":"stream"},{"name":"stderr","text":" 96%|| 96/100 [1:41:14<04:10, 62.69s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.22440722584724426, Val loss: 0.11725673824548721\nEPOCH: 96/100\n","output_type":"stream"},{"name":"stderr","text":" 97%|| 97/100 [1:42:16<03:08, 62.68s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.1913994401693344, Val loss: 0.12702597677707672\nEPOCH: 97/100\n","output_type":"stream"},{"name":"stderr","text":" 98%|| 98/100 [1:43:19<02:05, 62.68s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.17497336864471436, Val loss: 0.0940576121211052\nEPOCH: 98/100\n","output_type":"stream"},{"name":"stderr","text":" 99%|| 99/100 [1:44:22<01:02, 62.70s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.15834850072860718, Val loss: 0.14544665813446045\nEPOCH: 99/100\n","output_type":"stream"},{"name":"stderr","text":"100%|| 100/100 [1:45:25<00:00, 63.25s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.15969178080558777, Val loss: 0.13175024092197418\nEPOCH: 100/100\ntotal time taken to train the model: 6325.12s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Plotting Loss curve","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Example data\nx = list(range(1,len(train_loss)+1))  \nplt.plot(x, train_loss, label='train')  # Plot the first line and specify its label\nplt.plot(x, val_loss, label='val')  # Plot the second line and specify its label\n\n# Adding labels and title\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train loss', 'validation loss'])\nplt.savefig('loss_curve_binary.png', dpi=300) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:37:27.275384Z","iopub.execute_input":"2024-05-18T10:37:27.275697Z","iopub.status.idle":"2024-05-18T10:37:27.920323Z","shell.execute_reply.started":"2024-05-18T10:37:27.275669Z","shell.execute_reply":"2024-05-18T10:37:27.919441Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# For Test Evaluation","metadata":{}},{"cell_type":"code","source":"def get_accuracy(SR,GT,threshold=0.5):\n    SR = (SR > threshold)*1\n    GT = GT == torch.max(GT)\n    corr = torch.sum(SR==GT)\n    tensor_size = SR.size(0)*SR.size(1)*SR.size(2)*SR.size(3)\n    acc = float(corr)/float(tensor_size)\n\n    return acc\n\n# def get_sensitivity(SR,GT,threshold=0.5):\n#     # Sensitivity == Recall\n#     SR = (SR > threshold)*1\n#     GT = GT == torch.max(GT)\n\n#     # TP : True Positive\n#     # FN : False Negative\n#     TP = ((SR==1)+(GT==1))==2\n#     FN = ((SR==0)+(GT==1))==2\n\n#     SE = float(torch.sum(TP))/(float(torch.sum(TP+FN)) + 1e-6)     \n    \n#     return SE\n\n# def get_specificity(SR,GT,threshold=0.5):\n#     SR = (SR > threshold)*1\n#     GT = GT == torch.max(GT)\n\n#     # TN : True Negative\n#     # FP : False Positive\n#     TN = ((SR==0)+(GT==0))==2\n#     FP = ((SR==1)+(GT==0))==2\n\n#     SP = float(torch.sum(TN))/(float(torch.sum(TN+FP)) + 1e-6)\n    \n#     return SP\n\n# def get_precision(SR,GT,threshold=0.5):\n#     SR = (SR > threshold)*1\n#     GT = GT == torch.max(GT)\n\n#     # TP : True Positive\n#     # FP : False Positive\n#     TP = ((SR==1)+(GT==1))==2\n#     FP = ((SR==1)+(GT==0))==2\n\n#     PC = float(torch.sum(TP))/(float(torch.sum(TP+FP)) + 1e-6)\n\n#     return PC\n\ndef get_F1(SR,GT,threshold=0.5):\n    # Sensitivity == Recall\n    SE = get_sensitivity(SR,GT,threshold=threshold)\n    PC = get_precision(SR,GT,threshold=threshold)\n    \n    print(SE, PC)\n\n    F1 = 2*SE*PC/(SE+PC + 1e-6)\n\n    return F1\n\ndef calculate_f1_from_masks(y_pred, y_true, threshold=0.5):\n    y_true = y_true.flatten()\n    y_pred = (y_pred.flatten() > threshold)*1\n    \n    tp = torch.sum((y_true == 1) & (y_pred == 1))\n    fp = torch.sum((y_true == 0) & (y_pred == 1))\n    fn = torch.sum((y_true == 1) & (y_pred == 0))\n    \n    precision = tp / (tp + fp) if tp + fp > 0 else 0\n    recall = tp / (tp + fn) if tp + fn > 0 else 0\n    \n    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n    \n    if(f1>0):\n        return f1.cpu().numpy()\n    else:\n        return f1\n\n\ndef get_JS(SR,GT,threshold=0.5):   ##same as Jaccard index, IoU\n    # JS : Jaccard similarity\n    SR = (SR > threshold)*1\n    GT = GT == torch.max(GT)\n    \n    Inter = torch.sum((SR+GT)==2)\n    Union = torch.sum((SR+GT)>=1)\n    \n    JS = float(Inter)/(float(Union) + 1e-6)\n    \n    return JS\n\ndef get_DC(SR,GT,threshold=0.5):\n    # DC : Dice Coefficient\n    SR = (SR > threshold)*1\n    GT = GT == torch.max(GT)\n\n    Inter = torch.sum((SR+GT)==2)\n    DC = float(2*Inter)/(float(torch.sum(SR)+torch.sum(GT)) + 1e-6)\n\n    return DC","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:37:27.921535Z","iopub.execute_input":"2024-05-18T10:37:27.921866Z","iopub.status.idle":"2024-05-18T10:37:27.937105Z","shell.execute_reply.started":"2024-05-18T10:37:27.921834Z","shell.execute_reply":"2024-05-18T10:37:27.936106Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"totaltestacc = 0\ntotaltestloss = 0\ntotaltestJS = 0\ntotaltestdice = 0\ntotaltestf1 = 0\n\nmodel.load_state_dict(torch.load('model_weights.pth'))\n\nwith torch.no_grad():\n    model.eval()\n    # loop over the validation set\n    for i, (raw, gt) in enumerate(test_loader):\n        (raw, gt) = (raw.to(device), gt.to(device))\n        raw = raw.to(torch.float)\n        gt = gt.to(torch.float)\n        \n        pred = model(raw)[\"out\"]  ##only for deeplabv3\n        #pred = model(raw)\n        \n        pred = torch.sigmoid(pred)\n\n        totaltestloss += lossfunc(pred, gt)\n        totaltestacc += get_accuracy(pred, gt)\n        totaltestf1 += calculate_f1_from_masks(pred, gt)\n        totaltestJS += get_JS(pred, gt, threshold=0.5)\n        totaltestdice += get_DC(pred, gt, threshold=0.5)  ##dice score and F1 are almost same\n        #print(calculate_f1_from_masks(pred, gt))\n        \nprint(f\"total test loss {totaltestloss/i}, acc is {totaltestacc/i},f1 is {totaltestf1/i} dice is {totaltestdice/i}, JS is {totaltestJS/i}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:47:46.780291Z","iopub.execute_input":"2024-05-18T10:47:46.781173Z","iopub.status.idle":"2024-05-18T10:48:02.785046Z","shell.execute_reply.started":"2024-05-18T10:47:46.781143Z","shell.execute_reply":"2024-05-18T10:48:02.784039Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"total test loss 0.6864316463470459, acc is 0.9138595425352758,f1 is 0.6921657088155649 dice is 0.692165710610783, JS is 0.564917366728484\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('bin_scores.txt', 'w') as file:\n    file.write(f'Dice co-efficient: {totaltestdice/i}\\n')\n    file.write(f'Jaccard index: {totaltestJS/i}\\n')\n    file.write(f'Accuracy: {totaltestacc/i}\\n')\n    file.write(f'f1_score: {totaltestf1/i}\\n')\n    #file.write(f'classwise jaccard: {classwisescore}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:37:44.990158Z","iopub.execute_input":"2024-05-18T10:37:44.990512Z","iopub.status.idle":"2024-05-18T10:37:44.996166Z","shell.execute_reply.started":"2024-05-18T10:37:44.990479Z","shell.execute_reply":"2024-05-18T10:37:44.995231Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# g = gt.cpu().numpy()*255\n# cv2.imwrite('demo.png',g)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:54:38.163687Z","iopub.status.idle":"2024-05-14T17:54:38.164117Z","shell.execute_reply.started":"2024-05-14T17:54:38.163895Z","shell.execute_reply":"2024-05-14T17:54:38.163916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}